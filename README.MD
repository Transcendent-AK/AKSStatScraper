# How to use it
- pip install -r ./requirements.txt  
- after that just do python ./scrapeStatus.py

# Why was it made?
- So was easier to yoink it to eidosite.test

# Why many commits?
- From first commit to last commit we got json structure changes which was made after we saw the one we did first didn't met the requirements for what we were looking for

# requirements
- Pandas (for easier managment of the table)
- BeautifulSoup (for extracting the HTML)
- lxml (for extracting the xpath of the eidons)
- requests (for python be able to make get requests)
- json (for the conversion of what i want from the table)
